{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Spectrogram of a single audio file\n",
    "def save_spectrogram(curr_audio_path, curr_audio_name):\n",
    "    X, sr = librosa.load(curr_audio_path)  # librosa.load() returns an np array and sampling rate(by default 22050)\n",
    "    plt.specgram(X, Fs=22050)\n",
    "    plt.gca().axes.get_yaxis().set_visible(False)\n",
    "    plt.gca().axes.get_xaxis().set_visible(False)\n",
    "    plt.plot\n",
    "    plt.savefig('spectrograms/' + curr_audio_name,  bbox_inches= 'tight' , pad_inches = 0, dpi = 25)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " Now we have all the spectrogram images in the 'sprectograms' folder, we need to make our datasets: X and Y\n",
    " The file is in the format: [fsID]-[classID]-[occurrenceID]-[sliceID].wav (Now converted to an image)\n",
    " So to build 'Y' we can retrieve 'classID' from each of the file\n",
    " So we have to go to all the images, flatten each image into an array, \n",
    " append it to 'X' and store the corrsponding class values in 'Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "rootdir = 'spectrograms/'\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        curr_img_path = os.path.join(subdir, file)  # The path of current image file\n",
    "        curr_img_path = os.path.normpath(curr_img_path)  # To get '\\' instead of '/'\n",
    "        curr_img_name = os.path.splitext(file)[0]   # The name of current image file (withoud .png extension)\n",
    "        img = image.load_img(curr_img_path, target_size = (64, 64))  # Load the actual image file\n",
    "        img = image.img_to_array(img)        # Convert the loaded image file to the array\n",
    "        cls = int(curr_img_name.split('-')[1])\n",
    "        X.append(img)\n",
    "        Y.append(cls)\n",
    "print(len(X), len(Y))\n",
    "print(X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "Y = to_categorical(Y)   # One hot encoding\n",
    "X.shape, type(X), Y.shape, type(Y), (Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 0)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the CNN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now we have our training and testing data, we can now train our CNN model using this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_width = 64\n",
    "input_height = 64\n",
    "input_channels = 3\n",
    "input_shape = (input_width, input_height, input_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3),\n",
    "                 activation='relu', padding='same',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizers.rmsprop(lr=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=50, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539/539 [==============================] - 2s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.8971323836491147, 0.8256029486656189]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model, so that we can use this trained model later also\n",
    "model.save('saved_models/UrbanSoundComplete.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['air_conditioner', 'car_horn', 'children_playing', 'dog_bark', 'drilling', 'engine_idling', 'gun_shot', 'jackhammer', 'siren', 'street_music']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing on an audio file\n",
    "wav_path = 'testAudio0.wav'\n",
    "wav_name = os.path.splitext(wav_path)[0]\n",
    "save_spectrogram(wav_path, wav_name)\n",
    "png_path = 'spectrograms/' + wav_name + '.png'\n",
    "png_img = image.load_img(png_path, target_size = (64, 64))\n",
    "x = image.img_to_array(png_img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "pred = model.predict(x)\n",
    "class_idx = np.argmax(pred[0])\n",
    "predicted_class = class_names[class_idx]\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
