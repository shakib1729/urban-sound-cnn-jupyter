{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Spectrogram of a single audio file\n",
    "def save_spectrogram(curr_audio_path, curr_audio_name):\n",
    "    X, sr = librosa.load(curr_audio_path)  # librosa.load() returns an np array and sampling rate(by default 22050)\n",
    "    plt.specgram(X, Fs=22050)\n",
    "    plt.gca().axes.get_yaxis().set_visible(False)\n",
    "    plt.gca().axes.get_xaxis().set_visible(False)\n",
    "    plt.plot\n",
    "    plt.savefig('spectrograms/' + curr_audio_name,  bbox_inches= 'tight' , pad_inches = 0, dpi = 25)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " Now we have all the spectrogram images in the 'sprectograms' folder, we need to make our datasets: X and Y\n",
    " The file is in the format: [fsID]-[classID]-[occurrenceID]-[sliceID].wav (Now converted to an image)\n",
    " So to build 'Y' we can retrieve 'classID' from each of the file\n",
    " So we have to go to all the images, flatten each image into an array, \n",
    " append it to 'X' and store the corrsponding class values in 'Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8732 8732\n",
      "(64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "\n",
    "rootdir = 'spectrograms/'\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        curr_img_path = os.path.join(subdir, file)  # The path of current image file\n",
    "        curr_img_path = os.path.normpath(curr_img_path)  # To get '\\' instead of '/'\n",
    "        curr_img_name = os.path.splitext(file)[0]   # The name of current image file (withoud .png extension)\n",
    "        img = image.load_img(curr_img_path, target_size = (64, 64))  # Load the actual image file\n",
    "        img = image.img_to_array(img)        # Convert the loaded image file to the array\n",
    "        cls = int(curr_img_name.split('-')[1])\n",
    "        X.append(img)\n",
    "        Y.append(cls)\n",
    "print(len(X), len(Y))\n",
    "print(X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8732, 64, 64, 3),\n",
       " numpy.ndarray,\n",
       " (8732, 10),\n",
       " numpy.ndarray,\n",
       " array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "Y = to_categorical(Y)   # One hot encoding\n",
    "X.shape, type(X), Y.shape, type(Y), (Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6549, 64, 64, 3) (6549, 10)\n",
      "(2183, 64, 64, 3) (2183, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 0)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the CNN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now we have our training and testing data, we can now train our CNN model using this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_width = 64\n",
    "input_height = 64\n",
    "input_channels = 3\n",
    "input_shape = (input_width, input_height, input_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,210\n",
      "Trainable params: 407,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizers.Adam(lr=0.0005),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=50, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2183/2183 [==============================] - 3s 1ms/step\n",
      "[0.7213552639816695, 0.8405863642692566]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model, so that we can use this trained model later also\n",
    "model.save('saved_models/UrbanSoundCompleteCNNAdam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = model.predict(X_test)\n",
    "Y_train_pred = model.predict(X_train)\n",
    "y_test_pred = np.argmax(Y_test_pred, axis=1)\n",
    "y_test = np.argmax(Y_test, axis=1)\n",
    "y_train_pred = np.argmax(Y_train_pred, axis=1)\n",
    "y_train = np.argmax(Y_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[227   0   0   4   2   3   0   3   3   2]\n",
      " [  0  77   6   6   3   2   1   0   1   8]\n",
      " [  6   1 188  14   5  10   0   1   2  32]\n",
      " [  3   2  16 177   2   4   2   1   5  12]\n",
      " [  0   2   2  11 209   3   4  17   0   8]\n",
      " [ 12   1   9   3   1 230   1   2   1   6]\n",
      " [  1   0   0   1   1   0 100   1   0   3]\n",
      " [  2   1   1   1   3   0   0 220   0   8]\n",
      " [  5   0   2   3   1   2   0   0 223  16]\n",
      " [  9   9  13   5   4   4   0   2   5 184]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[756   0   0   0   0   0   0   0   0   0]\n",
      " [  0 324   0   0   0   0   0   0   0   1]\n",
      " [  1   0 735   0   0   0   0   0   0   5]\n",
      " [  1   1   0 774   0   0   0   0   0   0]\n",
      " [  0   0   1   0 738   0   0   5   0   0]\n",
      " [  7   0   2   1   0 723   0   1   0   0]\n",
      " [  0   0   0   0   0   0 267   0   0   0]\n",
      " [  0   0   0   0   0   0   0 764   0   0]\n",
      " [  0   0   0   0   0   0   0   0 676   1]\n",
      " [  5   0   0   0   0   0   0   2   0 758]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       244\n",
      "           1       0.83      0.74      0.78       104\n",
      "           2       0.79      0.73      0.76       259\n",
      "           3       0.79      0.79      0.79       224\n",
      "           4       0.90      0.82      0.86       256\n",
      "           5       0.89      0.86      0.88       266\n",
      "           6       0.93      0.93      0.93       107\n",
      "           7       0.89      0.93      0.91       236\n",
      "           8       0.93      0.88      0.91       252\n",
      "           9       0.66      0.78      0.72       235\n",
      "\n",
      "    accuracy                           0.84      2183\n",
      "   macro avg       0.85      0.84      0.84      2183\n",
      "weighted avg       0.84      0.84      0.84      2183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       756\n",
      "           1       1.00      1.00      1.00       325\n",
      "           2       1.00      0.99      0.99       741\n",
      "           3       1.00      1.00      1.00       776\n",
      "           4       1.00      0.99      1.00       744\n",
      "           5       1.00      0.99      0.99       734\n",
      "           6       1.00      1.00      1.00       267\n",
      "           7       0.99      1.00      0.99       764\n",
      "           8       1.00      1.00      1.00       677\n",
      "           9       0.99      0.99      0.99       765\n",
      "\n",
      "    accuracy                           0.99      6549\n",
      "   macro avg       1.00      1.00      1.00      6549\n",
      "weighted avg       0.99      0.99      0.99      6549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
